@ARTICLE{Werner2016-xh,
  title     = "Peptide backbone composition and protease susceptibility: Impact
               of modification type, position, and tandem substitution",
  author    = "Werner, Halina M and Cabalteja, Chino C and Horne, W Seth",
  abstract  = "The clinical utility of peptides is limited by their rapid
               degradation by endogenous proteases. Modification of the peptide
               backbone can generate functional analogues with enhanced
               proteolytic stability. Existing principles for the design of
               such oligomers have focused primarily on effective structural
               mimicry. A more robust strategy would incorporate a rational
               approach for engineering maximal proteolytic stability with
               minimal unnatural residue content. We report here the systematic
               comparison of the proteolytic resistance imparted by four
               backbone modifications commonly employed in the design of
               protease-stable analogues of peptides with complex folding
               patterns. The degree of protection was quantified as a function
               of modification type, position, and tandem substitution in the
               context of a long, unstructured host sequence and a canonical
               serine protease. These results promise to inform ongoing work to
               develop biostable mimics of increasingly complex peptides and
               proteins.",
  journal   = "Chembiochem",
  publisher = "Wiley",
  volume    =  17,
  number    =  8,
  pages     = "712--718",
  month     =  apr,
  year      =  2016,
  keywords  = "foldamers; peptides; peptidomimetics; proteases; protein-protein
               interactions",
  language  = "en"
}

@ARTICLE{Craik2006-wo,
  title     = "Chemistry. Seamless proteins tie up their loose ends",
  author    = "Craik, David J",
  journal   = "Science",
  publisher = "American Association for the Advancement of Science (AAAS)",
  volume    =  311,
  number    =  5767,
  pages     = "1563--1564",
  month     =  mar,
  year      =  2006,
  language  = "en"
}

@ARTICLE{Klein2024-ox,
  title        = "Transferable Boltzmann Generators",
  author       = "Klein, Leon and No{\'e}, Frank",
  abstract     = "The generation of equilibrium samples of molecular systems
                  has been a long-standing problem in statistical physics.
                  Boltzmann Generators are a generative machine learning method
                  that addresses this issue by learning a transformation via a
                  normalizing flow from a simple prior distribution to the
                  target Boltzmann distribution of interest. Recently, flow
                  matching has been employed to train Boltzmann Generators for
                  small molecular systems in Cartesian coordinates. We extend
                  this work and propose a first framework for Boltzmann
                  Generators that are transferable across chemical space, such
                  that they predict zero-shot Boltzmann distributions for test
                  molecules without being retrained for these systems. These
                  transferable Boltzmann Generators allow approximate sampling
                  from the target distribution of unseen systems, as well as
                  efficient reweighting to the target Boltzmann distribution.
                  The transferability of the proposed framework is evaluated on
                  dipeptides, where we show that it generalizes efficiently to
                  unseen systems. Furthermore, we demonstrate that our proposed
                  architecture enhances the efficiency of Boltzmann Generators
                  trained on single molecular systems.",
  year         =  2024,
  primaryClass = "stat.ML",
  eprint       = "2406.14426"
}

@ARTICLE{Lipman2022-er,
  title        = "Flow Matching for generative modeling",
  author       = "Lipman, Yaron and Chen, Ricky T Q and Ben-Hamu, Heli and
                  Nickel, Maximilian and Le, Matt",
  abstract     = "We introduce a new paradigm for generative modeling built on
                  Continuous Normalizing Flows (CNFs), allowing us to train
                  CNFs at unprecedented scale. Specifically, we present the
                  notion of Flow Matching (FM), a simulation-free approach for
                  training CNFs based on regressing vector fields of fixed
                  conditional probability paths. Flow Matching is compatible
                  with a general family of Gaussian probability paths for
                  transforming between noise and data samples -- which subsumes
                  existing diffusion paths as specific instances.
                  Interestingly, we find that employing FM with diffusion paths
                  results in a more robust and stable alternative for training
                  diffusion models. Furthermore, Flow Matching opens the door
                  to training CNFs with other, non-diffusion probability paths.
                  An instance of particular interest is using Optimal Transport
                  (OT) displacement interpolation to define the conditional
                  probability paths. These paths are more efficient than
                  diffusion paths, provide faster training and sampling, and
                  result in better generalization. Training CNFs using Flow
                  Matching on ImageNet leads to consistently better performance
                  than alternative diffusion-based methods in terms of both
                  likelihood and sample quality, and allows fast and reliable
                  sample generation using off-the-shelf numerical ODE solvers.",
  year         =  2022,
  primaryClass = "cs.LG",
  eprint       = "2210.02747"
}

